# Hành trình “Learning Path”cho Chương trình đào tạo Mastering Coding Khoa Học Dữ liệu "Mastering Coding Data Sciences"

_Cập nhật bài viết: vào ngày 28 tháng 9 năm 2024 trong Khoa học dữ liệu và Nghiên cứu đào tạo bộ môn Khoa học máy tính và Khoa học dữ liệu._

**Tham khảo:**

- Nvidia L4 , A4, T4, P4, H100, M60, K8,  vSphere ARM vs Cloud Edge IoT, K8s CNI.
- Breakthrough Universal Accelerator cho Video, AI và Đồ họa hiệu quả.

Tôi và các bạn muốn học cách lập trình cho khoa học dữ liệu?  Dưới đây là bảy bước này sẽ giúp bạn trong hành trình học tập của mình.
Tôi: Lê Toàn Thắng Tiến Sĩ Khoa Học ‘viết tắt: PhD. Le Toan Thang’.

- Biên tập viên cộng tác & Chuyên gia soạn nội dung kỹ thuật Labs Manager Hand On Labs và Mumbai Pact Published,
- Giám đốc nghiên cứu và Phát triển AI/ML/DL của AT.COM
- Tiêu chuẩn đào tạo quốc tế của CompTIA CIN về DataX – DY01.
- Giảng viên Quốc tế chuyên về Khoa học máy tính, Điện toán Đám mây và Khoa học Dữ liệu của CompTIA CIN CTTT+, Cloud+, DataX.

- Còn Bạn có phải là một nhà khoa học dữ liệu đầy tham vọng hay đang ở giai đoạn đầu của sự nghiệp khoa học dữ liệu?
- Nếu vậy, bạn nên biết rằng mình sẽ cần sử dụng các kỹ năng lập trình, thống kê, xác suất, tuyến tính hoặc phi tuyến tính, lượng tử và
  học máy của mình – cùng với các chuyên môn về lĩnh vực chuyên ngành từ kế toán, tài chính, kiểm toán, chứng khoán, ngân hàng, Kinh doanh bán lẻ, bán buôi,
  thu ngân, chuỗi sản xuất, quy trình cung ứng, phân phối, Phân tích tin – Y – Sinh Học cao phân tử, cộng hưởng từ trong y học lâm sàng khám và chuẩn đoán bệnh,
  thu thập và phân tích dữ liệu IoT…
để sử dụng dữ liệu và trả lời các câu hỏi kinh doanh, doanh thu hoặc chỉ số giúp điều chỉnh và hoàn thiện mô hình Kinh doanh.

```sum
Do đó, để thành công với tư cách là một nhà khoa học dữ liệu, việc trở nên thành thạo trong việc lập trình là điều cần thiết. 
Đặc biệt là để xử lý và phân tích các tập dữ liệu lớn, xây dựng và triển khai các mô hình học máy, v.v.
Bài viết nói đúng Bảy (07) bước thực tế từ tổng quát tới chi tiết để giúp bạn thành thạo mã hóa cho khoa học dữ liệu, 
cho dù bạn là người mới bắt đầu hay đang muốn nâng cao kỹ năng của mình.
```

## Bước 1: Học Python (hoặc R) và SQL
- Khi bắt đầu hành trình khoa học dữ liệu, bước đầu tiên là trở nên thành thạo một ngôn ngữ lập trình chuyên cho AI/ML.
- Chúng tôi khuyên bạn nên chọn Python. Nhưng nếu bạn chỉ muốn tập trung vào dữ liệu và phân tích thống kê, bạn cũng có thể chọn R.

## Những điều bạn nên tập trung vào, khi học Python, hãy tập trung vào:
1. Biến và kiểu dữ liệu: Hiểu các khối xây dựng cơ bản của lập trình, chẳng hạn như số nguyên, chuỗi, số thực và boolean.
1. Kiểm soát luồng: Tìm hiểu cách kiểm soát việc thực thi mã bằng vòng lặp, câu lệnh có điều kiện) và hàm.
1. Hàm và xử lý lỗi: Nắm vững nghệ thuật viết mã có thể tái sử dụng bằng cách tạo hàm và xử lý lỗi một cách khéo léo bằng khối `try–except`.
1. OOP: Cố gắng làm quen với lập trình hướng đối tượng trong Python.

## Và trên phần Dữ liệu dùng SQL, hãy làm việc trên:
1. Truy vấn cơ bản: Tìm hiểu cách truy xuất dữ liệu bằng SELECT, lọc bằng WHERE và sắp xếp dữ liệu bằng ORDER BY.
1. Kết nối và tổng hợp ‘Joins and aggregations’: Nắm vững cách kết hợp dữ liệu từ nhiều bảng bằng cách nối và
   thực hiện các phép tính tổng hợp bằng các hàm phổ biến như SUM(), AVG() và COUNT().
1. Mục tiêu: Sau khi bạn đã học Python (hoặc R) để thao tác dữ liệu và SQL để quản lý cơ sở dữ liệu, bạn sẽ có thể xử lý cả tập dữ liệu trong bộ nhớ và
   dữ liệu được lưu trữ trong cơ sở dữ liệu. Điều này rất quan trọng trước khi bạn có thể tiến xa hơn.

## Tài nguyên:
- Python cho mọi người: https://www.youtube.com/watch?v=8DvywoWv6fI
- SQL trực quan cho phân tích Dữ liệu: https://www.youtube.com/watch?v=mXW7JHJM34k
- Hướng dẫn lập trình R: https://www.youtube.com/watch?v=_V8eKsto3Ug

## Bước 2: Làm quen với thao tác dữ liệu:
1. Thao tác dữ liệu là một trong những kỹ năng quan trọng nhất trong khoa học dữ liệu. Trước khi bạn có thể phân tích hoặc lập mô hình dữ liệu,
   bạn phải dọn dẹp và chuyển đổi dữ liệu thành định dạng có thể sử dụng được.
1. Trong Python, thư viện pandas là công cụ cần thiết cho việc này. Trong khi R có các thư viện mạnh mẽ như dplyr cho các tác vụ tương tự.
1. Hiểu các kỹ thuật thao tác dữ liệu cho phép bạn nhanh chóng chuẩn bị dữ liệu để phân tích và là nền tảng để xây dựng mô hình.

## Những điều bạn nên tập trung vào
1. Lọc dữ liệu: Tìm hiểu cách chọn các tập hợp con dữ liệu dựa trên các điều kiện.
1. Nhóm và tổng hợp: Làm quen với việc tóm tắt dữ liệu bằng các hàm như groupby() và các hàm tổng hợp trong pandas.
1. Hợp nhất và định hình lại: Tìm hiểu cách hợp nhất nhiều tập dữ liệu và định hình lại dữ liệu (sử dụng bảng trục) để đáp ứng nhu cầu phân tích của bạn.

## Tài nguyên:
- Phân tích dữ liệu bằng Python: https://www.youtube.com/watch?v=GPVsHOlRBBI
- Pandas & Python để phân tích dữ liệu bằng ví dụ: https://www.youtube.com/watch?v=gtjxAH8uaP0

## Bước 3: Học trực quan hóa dữ liệu:
- Trực quan hóa dữ liệu hiệu quả cho phép bạn hiểu dữ liệu của mình tốt hơn và khám phá các mô hình và mối quan hệ không hiển thị ngay trong dữ liệu thô.
- Trực quan hóa dữ liệu rất quan trọng đối với cả phân tích dữ liệu thăm dò (EDA) và trình bày các phát hiện cho các bên liên quan.
- Bạn nên học cách làm việc với các thư viện Python như Matplotlib, Seaborn và Plotly. Hoặc ggplot2 nếu bạn thích R.

## Những điều bạn nên tập trung vào:
1. Biểu đồ cơ bản: Hiểu cách tạo biểu đồ đường, biểu đồ thanh, biểu đồ phân tán và biểu đồ histogram để trực quan hóa dữ liệu của bạn.
1. Biểu đồ nâng cao hơn: Tìm hiểu cách trực quan hóa phân phối, tương quan (sử dụng bản đồ nhiệt) và dữ liệu chuỗi thời gian.
1. Trực quan hóa tương tác: Tìm hiểu cách sử dụng các công cụ như Plotly để tạo bảng thông tin và đồ thị tương tác-hữu ích cho các bài thuyết trình và báo cáo.

## Tài nguyên:
- Học trực quan hóa dữ liệu | Kaggle: https://www.kaggle.com/learn/data-visualization
- Khóa học Phân tích dữ liệu bằng Python – Numpy, Pandas, Hình dung dữ liệu: https://www.youtube.com/watch?v=GPVsHOlRBBI

## Bước 4: Tìm hiểu các thuật toán học máy:
- Khi bạn đã hiểu rõ về phân tích và trực quan hóa dữ liệu, như đã nêu trong các bước trước, bước hợp lý tiếp theo là tìm hiểu về các thuật toán ML.
- Scikit–learn là một thư viện mạnh mẽ và dễ sử dụng cho mục đích này.

## Những điều bạn nên tập trung vào:
Bạn nên tập trung vào các thuật toán sau, các giả định mà chúng dựa vào, các trường hợp sử dụng và các hạn chế:
1. Hồi quy tuyến tính ‘Linear regression’.
1. Hồi quy logistic ‘Logistic regression’.
1. Cây ra quyết định và Cánh rừng ngẫu nhiên ‘Decision Trees and Random Forests’.
1. Phân cụm ‘Clustering’.
1. Tăng cường độ dốc ‘Gradient Boosting’.

## Tài nguyên:
- Giới thiệu về học máy | Kaggle: https://www.kaggle.com/learn/intro-to-machine-learning
- Học máy trung cấp | Kaggle: https://www.kaggle.com/learn/intermediate-machine-learning

## Bước 5: Tìm hiểu về Containerization và Phát triển API:
- Khi bạn tiến xa hơn trong hành trình khoa học dữ liệu của mình, điều quan trọng là phải hiểu cách triển khai các mô hình và chia sẻ công việc của bạn.
- Các công cụ Containerization như Docker cho phép bạn đóng gói mã và các phụ thuộc của mình trong một môi trường nhất quán,
  trong khi API giúp đưa các mô hình của bạn đến với những người khác thông qua các dịch vụ web.
Những kỹ năng này rất cần thiết để giúp các dự án khoa học dữ liệu của bạn di động và có thể mở rộng hơn.

## Những điều bạn nên tập trung vào:
1. Các công cụ Containerization: Containerization đảm bảo rằng các ứng dụng của bạn chạy nhất quán trên các hệ thống – loại bỏ vấn đề “hoạt động trên máy của tôi”.
1. Tìm hiểu cách sử dụng các công cụ Containerization như Docker để đóng gói các ứng dụng của bạn.
1. Kiến thức cơ bản về Docker: Bắt đầu bằng cách làm quen với việc tạo Dockerfile, xây dựng hình ảnh và chạy container.
1. Tìm hiểu cách sử dụng các khối lượng và tính năng mạng để lưu trữ dữ liệu và giao tiếp giữa các dịch vụ.
1. Các phương pháp hay nhất: Đảm bảo rằng bạn đang xây dựng các container nhỏ, hiệu quả và quen thuộc với việc quản lý các phụ thuộc và mối quan tâm về bảo mật.
1. Phát triển API với Flask hoặc FastAPI: Xây dựng các API REST nhẹ cho phép người dùng hoặc hệ thống tương tác với các mô hình khoa học dữ liệu của bạn.
1. Flask: Bắt đầu với những điều cơ bản về thiết lập điểm cuối API đơn giản, sau đó chuyển sang các tính năng phức tạp hơn như xử lý yêu cầu POST, xác thực và phục vụ mô hình.
1. FastAPI: Học cách xây dựng API không đồng bộ để ứng dụng nhanh hơn, hiệu quả hơn.

## Tài nguyên:
- Hướng dẫn FastAPI: https://fastapi.tiangolo.com/tutorial/
- Hướng dẫn Docker cho người mới bắt đầu: https://www.youtube.com/watch?v=3c-iBn73dDE

## Bước 6: Thực hành làm việc với các tập dữ liệu lớn:
- Khoa học dữ liệu thường liên quan đến việc xử lý dữ liệu vượt quá dung lượng bộ nhớ của máy cục bộ của bạn.
- Học cách làm việc hiệu quả với các tập dữ liệu lớn là điều quan trọng để mở rộng quy mô phân tích và mô hình của bạn.
- Các công cụ như Dask (https://www.dask.org/ ) và PySpark (https://spark.apache.org/docs/latest/api/python/index.html ) trong Python cho phép xử lý dữ liệu song song.
- Chúng cho phép bạn làm việc với các tập dữ liệu thực tế thường quá lớn để phù hợp với bộ nhớ.

## Những điều bạn nên tập trung vào:
1. Phân vùng dữ liệu: Học cách chia tập dữ liệu của bạn thành các phần nhỏ hơn, dễ quản lý và xử lý chúng.
1. Điện toán phân tán: Sử dụng các khung như `Dask` hoặc `PySpark` để xử lý các tập dữ liệu lớn song song trên nhiều máy.
1. Nâng cao kỹ năng SQL của bạn: Trở nên thành thạo SQL và Spark SQL để truy vấn cơ sở dữ liệu lớn một cách hiệu quả và chỉ truy xuất dữ liệu bạn cần.

## Tài nguyên:
- Hướng dẫn Dask: https://tutorial.dask.org/00_overview.html
- Hướng dẫn PySpark: https://www.youtube.com/watch?v=_C8kWso4ne4

## Bước 7: Xây dựng dự án và cộng tác:
- Bước quan trọng nhất để thành thạo mã hóa cho khoa học dữ liệu là áp dụng mọi thứ bạn đã học thông qua các dự án thực hành.
- Xây dựng các dự án thực tế không chỉ củng cố kỹ năng của bạn mà còn chứng minh chuyên môn của bạn với các nhà tuyển dụng tiềm năng và
  danh mục đầu tư của bạn sẽ nói lên kinh nghiệm và chuyên môn của bạn.
- Cộng tác với những người học khác và các chuyên gia giàu kinh nghiệm và đóng góp vào các dự án nguồn mở có thể nâng cao kỹ năng lập trình của bạn.

## Những điều bạn nên tập trung vào:
1. Bắt đầu với các nhiệm vụ sắp xếp dữ liệu đơn giản và chuyển sang các vấn đề phức tạp hơn đòi hỏi các giải pháp tinh vi hơn.
1. Tham gia các cuộc thi Kaggle, CompTIA, Microsoft Azure, Amazon, Google, NVIDIA và các cuộc thi khác do cộng đồng khoa học dữ liệu tổ chức để giải quyết các vấn đề thực tế.
1. Đóng góp vào các dự án khoa học dữ liệu nguồn mở trên GitHub hoặc GitLabs hoặc Azure DevOps để cải thiện kỹ năng lập trình và cộng tác của bạn.
1. Xây dựng và chia sẻ các dự án giúp bạn có được kinh nghiệm thực tế, củng cố kỹ năng của mình và tạo danh mục đầu tư giới thiệu công việc của bạn.

## Tóm lại:
- Học lập trình cho khoa học dữ liệu liên quan đến việc có được nền tảng vững chắc về lập trình, hiểu biết tốt về phân tích và trực quan hóa dữ liệu và
  xây dựng các mô hình học máy.
- Ngoài ra, container hóa và phát triển API là những kỹ năng thiết yếu giúp bạn triển khai và mở rộng mô hình.
- Nếu bạn quan tâm đến việc học toán cho khoa học dữ liệu, hãy đọc 07 bước trên đây để thành thạo toán,
thuật toán vận dụng linh hoạt cũng như sử dụng Python, Jupyter notebook, Open-WebUI để lưu các dự án thành Project templates/simulator hoặc
build AI/LLAMA Models tạo nội sinh LLMA mô hình trên Web local giúp cho khoa học dữ liệu.
